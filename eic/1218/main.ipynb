{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d78555e5-8c64-4039-a867-800b3a8f142e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. mac_addr csv 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42e407f4-11ec-4678-ac5e-17490eb73035",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "read csv"
    }
   },
   "outputs": [],
   "source": [
    "# csv path\n",
    "csv_path = \"file:/Workspace/EIC_데이터엔지니어/databricks_jira/eic/1218/mac_addr.csv\"\n",
    "\n",
    "# spark dataframe \n",
    "df = (spark.read\n",
    "      .format(\"csv\")\n",
    "      .option(\"header\", True)           # 첫 행을 컬럼명으로 사용\n",
    "      .option(\"inferSchema\", True)      # 간단한 경우 자동 스키마 추론\n",
    "      # .option(\"delimiter\", \",\")       # 구분자 기본은 ',' (필요 시 지정)\n",
    "      # .option(\"encoding\", \"utf-8\")    # 인코딩 필요 시 지정\n",
    "      .load(csv_path)\n",
    "     )\n",
    "    \n",
    "# 맥 값 전처리 \n",
    "from pyspark.sql import functions as F\n",
    "df = df.withColumn(\n",
    "    \"mac_addr_2\",\n",
    "    F.concat_ws(\n",
    "        \":\",\n",
    "        F.substring(\"MAC_ADDRESS\", 1, 2),\n",
    "        F.substring(\"MAC_ADDRESS\", 3, 2),\n",
    "        F.substring(\"MAC_ADDRESS\", 5, 2),\n",
    "        F.substring(\"MAC_ADDRESS\", 7, 2),\n",
    "        F.substring(\"MAC_ADDRESS\", 9, 2),\n",
    "        F.substring(\"MAC_ADDRESS\", 11, 2),\n",
    "    )\n",
    ")\n",
    "\n",
    "# 맥 해쉬 처리\n",
    "tv_salt = dbutils.secrets.get('admin', 'salt')\n",
    "\n",
    "df = df.withColumn(\"mac_addr_hashed\", \n",
    "                   F.when(\n",
    "                       F.col(\"mac_addr_2\").isNull() | (F.col(\"mac_addr_2\") == ''), \n",
    "                       None)\\\n",
    "                    .otherwise(F.sha2(F.concat(F.col(\"mac_addr_2\"), F.lit(tv_salt)), 256)))\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "330ec3d9-8b5e-42a8-a321-953db00a38c3",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1767945136119}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# sdf -> pdf \n",
    "pdf = df.toPandas()\n",
    "pdf.columns = ['_'.join(col.split(' ')) for col in pdf.columns]\n",
    "pdf = pdf[['Production_Date'\n",
    "           , 'Model.Suffix'\n",
    "           , 'SET_ID'\n",
    "           , 'MAC_ADDRESS'\n",
    "           , 'mac_addr_hashed']]\n",
    "pdf = pdf.reset_index(drop=False)\n",
    "display(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da3dfc5f-73d0-4bd1-bebc-e9520dc84323",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.createDataFrame(pdf[['index', 'mac_addr_hashed']]).createOrReplaceTempView(\"tmp_mac_addr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6152fb46-88c7-438e-bc16-f08f67d9d113",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. activation_date - min(crt_date) 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d884e606-f670-4d31-a7f7-560712da9b8f",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1767947315611}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_result_1 = spark.sql(f''' \n",
    "    \n",
    "    select raw.mac_addr\n",
    "           , min(raw.crt_date) as min_crt_date \n",
    "           , first(raw.Platform_code) as platform_code \n",
    "           , max(raw.last_chg_date) as max_last_chg_date\n",
    "           , date_format(max(raw.last_chg_date), 'yyyy-MM') as last_chg_date_ym\n",
    "    from   eic_data_ods.tlamp.activation_date raw\n",
    "    inner join tmp_mac_addr tmp on raw.mac_addr = tmp.mac_addr_hashed\n",
    "    group by mac_addr\n",
    "''')\n",
    "display(df_result_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb93f0df-b39c-45e4-8666-32da795607a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_result_1\\\n",
    "    .write.mode('overwrite')\\\n",
    "    .option(\"mergeSchema\", \"true\")\\\n",
    "    .saveAsTable(f\"sandbox.z_eunmi1_ko.temp_1218_1\") # 중간 저장 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3727562a-3c47-4a2c-885d-3ab04b325ca6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3. 노말로그 값 구하기\n",
    "> 3-1) max_last_chg_date를 yyyy-MM 로 바꾸고, date_ym별 mac_addr 대한 마지막 normal_log 추출 (union 활용) <br/>\n",
    "> 3-2) 단, max_last_chg_date < '2025-12' 이면, 데이터 없음으로 추출 (2년 보관 중)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa06b4ab-ea63-47a9-8f0a-09c2b9b4f758",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "list_date_ym = []\n",
    "df_result_1 = spark.table(\"sandbox.z_eunmi1_ko.temp_1218_1\")\n",
    "for row in df_result_1.select(\"last_chg_date_ym\").distinct().collect():\n",
    "    list_date_ym.append(row.last_chg_date_ym)\n",
    "print(tuple(list_date_ym))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83861700-0ba5-4783-8288-064cc18cf54d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_result_2 = spark.sql(f'''\n",
    "    select nl.mac_addr\n",
    "           , nl.log_create_time\n",
    "           , nl.DEVICE_NAME \n",
    "           , nl.X_Device_Product \n",
    "           , nl.X_Device_FW_Version\n",
    "       --     , nl.ip_addr \n",
    "       --     , nl.accum_run_time\n",
    "       --     , nl.context_name\n",
    "       --     , nl.message_id\n",
    "       --     , nl.normal_log\n",
    "       --     , nl.REPORT_TIME\n",
    "       --     , nl.PRODUCT_NUM \n",
    "       --     , nl.BUILD_ID \n",
    "       --     , nl.BUILD_NAME \n",
    "       --     , nl.RELEASE_NUMBER \n",
    "       --     , nl.X_Device_Type \n",
    "       --     , nl.X_Device_SDK_VERSION \n",
    "       --     , nl.X_Device_Model \n",
    "       --     , nl.X_Device_Eula \n",
    "       --     , nl.X_Device_Netcast_Platform_Version \n",
    "       --     , nl.X_Device_Brand \n",
    "       --     , nl.X_Device_Locale \n",
    "       --     , nl.X_Device_Eco_Info \n",
    "       --     , nl.X_Device_Publish_Flag \n",
    "       --     , nl.X_Device_Platform \n",
    "       --     , nl.X_Device_Language \n",
    "       --     , nl.X_Device_FCK \n",
    "       --     , nl.X_Device_Country \n",
    "       --     , nl.X_Device_Country_Group \n",
    "       --     , nl.X_Device_Sales_Model \n",
    "       --     , nl.date_ym\n",
    "    from   eic_data_ods.tlamp.normal_log_webos25 nl\n",
    "    inner join tmp_mac_addr mac on nl.mac_addr = mac.mac_addr_hashed\n",
    "    where  nl.date_ym in {tuple(list_date_ym)}\n",
    "      and  nl.X_device_country = 'TR'\n",
    "''')\n",
    "\n",
    "display(df_result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5713991-8e9b-4e4d-9c9a-1059dbc68cf6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "\n",
    "# Window 정의\n",
    "window_spec = Window.partitionBy(\"mac_addr\").orderBy(F.col(\"date_ym\").desc(), \n",
    "                                                     F.col(\"log_create_time\").desc())\n",
    "\n",
    "# rank() 적용\n",
    "df_result_2 = df_result_2.withColumn(\"rn\", F.rank().over(window_spec))\n",
    "\n",
    "# rn = 1 조건 필터링\n",
    "df_result_3 = df_result_2.filter(F.col(\"rn\") == 1).select(\"*\").drop(\"rn\")\n",
    "\n",
    "display(df_result_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44d3159d-f127-4ab9-a857-3f2dd262addd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_result_3\\\n",
    "    .write.mode('overwrite')\\\n",
    "    .option(\"mergeSchema\", \"true\")\\\n",
    "    .saveAsTable(f\"sandbox.z_eunmi1_ko.temp_1218_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fe5f876-6618-4c0c-89bd-558d8afbb4d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 최종 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "003d13c9-4961-4975-b35a-26db2871a8c1",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1768363771954}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql \n",
    "select mac.index\n",
    "       , res1.min_crt_date\n",
    "       , res1.platform_code\n",
    "       , res3.log_create_time\n",
    "       , res3.DEVICE_NAME\n",
    "       , res3.X_Device_Product\n",
    "       , res3.X_Device_FW_Version\n",
    "from tmp_mac_addr mac\n",
    "left join sandbox.z_eunmi1_ko.temp_1218_1 res1 on mac.mac_addr_hashed = res1.mac_addr \n",
    "left join sandbox.z_eunmi1_ko.temp_1218_3 res3 on mac.mac_addr_hashed = res3.mac_addr\n",
    ";\n",
    "\n",
    "-- csv 다운 후, mac_addr 컬럼은 수기 삭제. 이후, 전달 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "89f61a8d-03d3-4d98-9a4f-e7f19407f642",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8131258919606968,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "main",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}