{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d78555e5-8c64-4039-a867-800b3a8f142e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. mac_addr csv 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42e407f4-11ec-4678-ac5e-17490eb73035",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "read csv"
    }
   },
   "outputs": [],
   "source": [
    "# csv path\n",
    "csv_path = \"file:/Workspace/EIC_데이터엔지니어/databricks_jira/eic/1218/mac_addr.csv\"\n",
    "\n",
    "# spark dataframe \n",
    "df = (spark.read\n",
    "      .format(\"csv\")\n",
    "      .option(\"header\", True)           # 첫 행을 컬럼명으로 사용\n",
    "      .option(\"inferSchema\", True)      # 간단한 경우 자동 스키마 추론\n",
    "      # .option(\"delimiter\", \",\")       # 구분자 기본은 ',' (필요 시 지정)\n",
    "      # .option(\"encoding\", \"utf-8\")    # 인코딩 필요 시 지정\n",
    "      .load(csv_path)\n",
    "     )\n",
    "    \n",
    "# 맥 값 전처리 \n",
    "from pyspark.sql import functions as F\n",
    "df = df.withColumn(\n",
    "    \"mac_addr_2\",\n",
    "    F.concat_ws(\n",
    "        \":\",\n",
    "        F.substring(\"MAC_ADDRESS\", 1, 2),\n",
    "        F.substring(\"MAC_ADDRESS\", 3, 2),\n",
    "        F.substring(\"MAC_ADDRESS\", 5, 2),\n",
    "        F.substring(\"MAC_ADDRESS\", 7, 2),\n",
    "        F.substring(\"MAC_ADDRESS\", 9, 2),\n",
    "        F.substring(\"MAC_ADDRESS\", 11, 2),\n",
    "    )\n",
    ")\n",
    "\n",
    "# 맥 해쉬 처리\n",
    "tv_salt = dbutils.secrets.get('admin', 'salt')\n",
    "\n",
    "df = df.withColumn(\"mac_addr_hashed\", \n",
    "                   F.when(\n",
    "                       F.col(\"mac_addr_2\").isNull() | (F.col(\"mac_addr_2\") == ''), \n",
    "                       None)\\\n",
    "                    .otherwise(F.sha2(F.concat(F.col(\"mac_addr_2\"), F.lit(tv_salt)), 256)))\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "330ec3d9-8b5e-42a8-a321-953db00a38c3",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1767945136119}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# sdf -> pdf \n",
    "pdf = df.toPandas()\n",
    "pdf.columns = ['_'.join(col.split(' ')) for col in pdf.columns]\n",
    "pdf = pdf[['Production_Date'\n",
    "           , 'Model.Suffix'\n",
    "           , 'SET_ID'\n",
    "           , 'MAC_ADDRESS'\n",
    "           , 'mac_addr_hashed']]\n",
    "pdf = pdf.reset_index(drop=False)\n",
    "display(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da3dfc5f-73d0-4bd1-bebc-e9520dc84323",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.createDataFrame(pdf[['mac_addr_hashed']]).createOrReplaceTempView(\"tmp_mac_addr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6152fb46-88c7-438e-bc16-f08f67d9d113",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. activation_date - min(crt_date) 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d884e606-f670-4d31-a7f7-560712da9b8f",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1767947315611}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_result_1 = spark.sql(f''' \n",
    "    \n",
    "    select raw.mac_addr\n",
    "           , min(raw.crt_date) as min_crt_date -- 제공해야함\n",
    "           , first(raw.Platform_code) as platform_code -- 제공해야함\n",
    "           , max(raw.last_chg_date) as max_last_chg_date\n",
    "           , date_format(max(raw.last_chg_date), 'yyyy-MM') as date_ym\n",
    "    from   eic_data_ods.tlamp.activation_date raw\n",
    "    inner join tmp_mac_addr tmp on raw.mac_addr = tmp.mac_addr_hashed\n",
    "    group by mac_addr\n",
    "''')\n",
    "display(df_result_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3727562a-3c47-4a2c-885d-3ab04b325ca6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3. 노말로그 값 구하기\n",
    "> 3-1) max_last_chg_date를 yyyy-MM 로 바꾸고, date_ym별 mac_addr 대한 마지막 normal_log 추출 (union 활용) <br/>\n",
    "> 3-2) 단, max_last_chg_date < '2025-12' 이면, 데이터 없음으로 추출 (2년 보관 중)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f80c43e-55bb-4f61-99fe-7ec538b5e474",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql \n",
    "SELECT\n",
    "    X_device_platform as `platform_code`,  -- 필수 열\n",
    "    X_device_product as `platform_version`,-- 필수 열\n",
    "    X_Device_Country as `country_code`,    -- 필수/조건 열\n",
    "    log_create_time,                       -- 필수/조건 열\n",
    "    X_Device_SDK_VERSION as `dpv`,\n",
    "    mac_addr as `device_id`,               -- 필수 열  \n",
    "    x_device_sales_model as `sales_model_code`, -- 필수 열\n",
    "    context_name,                          -- 필수/조건 열  \n",
    "    message_id,                            -- 필수/조건 열\n",
    "    normal_log\n",
    "FROM eic_data_ods.tlamp.normal_log_webos23\n",
    "WHERE 1=1\n",
    "    AND X_device_country = 'TR' -- 튀르키예\n",
    "    AND context_name = ''\n",
    "    AND message_id = ''\n",
    "    AND date_ym >= ''\n",
    "    AND date_ym < ''\n",
    "ORDER BY date_format(log_create_time, 'yyyy-MM')\n",
    " "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4945575815127709,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "main",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}